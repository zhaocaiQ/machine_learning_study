{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "파이토치_ LSTM_predict.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP1qVUDlQbCOmmt1DpPR+76",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhaocaiQ/machine_learning_study/blob/master/%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98__LSTM_predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cetAd_YF3x38"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchtext.legacy import data,datasets\n",
        "import random"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOwwDcxO3z4x"
      },
      "source": [
        "SRC = data.Field(tokenize = 'spacy', lower = True)\n",
        "TRG = data.LabelField(dtype = torch.int64)\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(SRC, TRG) # download imdb dataset"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frOtpUty4C7C",
        "outputId": "6f97f206-cf4c-48bd-fe32-f492466131ed"
      },
      "source": [
        "# display single example at index 0\n",
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['i', 'always', 'enjoyed', 'watching', 'this', 'when', 'it', 'came', 'on', 'television', 'during', 'prime', '-', 'time', 'every', 'year', 'in', 'the', '60', \"'s\", '.', 'it', \"'s\", 'a', 'typical', 'hollywood', 'history', 'epic', ',', 'dramatized', ',', 'stylized', 'and', 'full', 'of', 'inaccuracies', 'but', 'so', 'what', ',', 'it', \"'s\", 'an', 'entertaining', 'movie', 'and', 'a', 'good', 'looking', 'film', '.', 'cecil', 'b.', 'demille', 'at', 'the', 'end', 'of', 'his', 'life', 'is', 'the', 'executive', 'producer', 'of', 'this', 'remake', 'of', 'his', '1938', 'film', '.', 'his', 'son', '-', 'in', '-', 'law', 'actor', 'anthony', 'quinn', 'who', 'had', 'the', 'supporting', 'role', 'of', 'beluche', 'in', 'the', \"'\", '38', 'film', 'is', 'the', 'director', 'in', 'his', 'directorial', 'debut', 'and', 'swan', 'song', 'as', 'he', 'had', 'never', 'directed', 'a', 'film', 'before', 'and', 'never', 'would', 'again', '.', 'demille', 'assembled', 'a', 'crew', 'who', 'had', 'recently', 'worked', 'on', 'his', '10', 'commandments', 'to', 'help', 'quinn', 'pull', 'it', 'off', 'including', 'longtime', 'demille', 'associate', 'producer', '/', 'actor', 'henry', 'wilcoxon', 'overseeing', 'the', 'project', '.', 'also', 'from', 'the', '10', 'commandments', 'are', 'screenwriter', 'jesse', 'lasky', ',', 'cinematographer', 'loyalk', 'griggs', ',', 'assistant', 'director', 'francisco', 'day', ',', '2nd', 'unit', 'director', 'arthur', 'rosson', ',', 'art', 'directors', 'walter', 'tyler', 'and', 'hal', 'pereira', ',', 'set', 'directors', 'sam', 'comer', 'and', 'ray', 'moyer', ',', 'costume', 'designers', 'edith', 'head', ',', 'john', 'jensen', 'and', 'ralph', 'lester', 'who', 'as', 'a', 'costume', 'design', 'team', 'received', 'the', 'buccaneer', \"'s\", 'only', 'oscar', 'nomination', '.', 'a', 'great', 'cast', 'here', 'from', 'team', 'demille', 'headed', 'up', 'by', 'yul', 'brynner', 'as', 'pirate', 'jean', 'lafitte', 'and', 'charleton', 'heston', 'as', 'future', 'president', 'general', 'andrew', 'jackson', '.', 'also', 'in', 'the', 'cast', 'are', 'charles', 'boyer', ',', 'e.g.', 'marshall', ',', 'lorne', 'greene', ',', 'claire', 'bloom', 'and', 'inger', 'stevens', '.', 'at', 'just', 'over', 'two', 'hours', 'it', 'drags', 'in', 'some', 'spots', 'but', 'makes', 'up', 'for', 'it', 'with', 'some', 'excellent', 'battle', 'scenes', '.', 'i', 'would', 'give', 'it', 'a', '7.5', 'out', 'of', '10', '.'], 'label': 'pos'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9ePM-_e4VKo",
        "outputId": "1963cadd-3696-42a2-a4e9-59d9511a1517"
      },
      "source": [
        "# Build vocabulary for source and target from training data\n",
        "\n",
        "SRC.build_vocab(train_data, max_size=10000, min_freq=5, vectors=\"glove.6B.100d\")  # using pretrained word embedding\n",
        "TRG.build_vocab(train_data, min_freq = 5)\n",
        "\n",
        "print(vars(TRG.vocab))\n",
        "print(f\"Unique tokens in source vocabulary: {len(SRC.vocab)}\")\n",
        "print(f\"Unique tokens in TRG vocabulary: {len(TRG.vocab)}\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'freqs': Counter({'pos': 12500, 'neg': 12500}), 'itos': ['neg', 'pos'], 'unk_index': None, 'stoi': defaultdict(None, {'neg': 0, 'pos': 1}), 'vectors': None}\n",
            "Unique tokens in source vocabulary: 10002\n",
            "Unique tokens in TRG vocabulary: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yUIB6xMD5gD"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "# train and test iteartor\n",
        "train_iterator,test_iterator = data.BucketIterator.splits(\n",
        "      (train_data, test_data), \n",
        "      batch_size = BATCH_SIZE, \n",
        "      device = device\n",
        "    )"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Akonp_2T5YEf"
      },
      "source": [
        "# Model class\n",
        "class Model(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim,emb_dim, hidden_dim, n_layers, dropout):\n",
        "    # input_dim <--- vocabulary size\n",
        "    # output_dim <--- len ([positive, negative]) == 2 \n",
        "    # emb_dim <--- embedding dimension of embedding matrix\n",
        "    \n",
        "    super(Model, self).__init__()\n",
        "    self.n_layers = n_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "    \n",
        "    self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "    self.rnn = nn.LSTM(emb_dim, hidden_dim, n_layers, dropout=dropout)\n",
        "    \n",
        "    self.fc1 = nn.Linear(hidden_dim, hidden_dim//2)\n",
        "    self.fc2 = nn.Linear(hidden_dim//2, output_dim)\n",
        "    \n",
        "    self.relu = nn.ReLU()\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, src):\n",
        "    # shape: [source_len, batch_size]\n",
        "    embedded = self.dropout(self.embedding(src)) # sahpe: [src_len, batch_size, embed_dim]\n",
        "    output, (hidden, cell) = self.rnn(embedded) \n",
        "    # output shape -> [batch, hidden_dim]\n",
        "    # hiddden shape -> [n_layers, batch, hidden_dim]\n",
        "    # cell shape -> [n_layers, batch, hidden_dim]\n",
        "    output = self.fc1(output[-1])\n",
        "    output = self.fc2(self.relu(output))\n",
        "    return output"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOda9j685dFH",
        "outputId": "c3c7dfa9-4f2a-4064-d8fe-8d15bdfe180e"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#initializing variables and hyper parameters\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "OUTPUT_DIM = len(LABEL.vocab)\n",
        "ENC_EMB_DIM = 100\n",
        "DEC_EMB_DIM = 100\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "# initializing our model\n",
        "model = Model(INPUT_DIM, OUTPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT).to(device)\n",
        "\n",
        "# loading pretrained word embedding\n",
        "model.embedding.weight.data.copy_(TEXT.vocab.vectors) "
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        ...,\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [-0.1915, -0.2686,  0.0245,  ..., -0.4086, -0.5865,  0.0474],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COb9h6KNDL1R"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=3e-3)\n",
        "\n",
        "# defining learnig rate scheduler (optional)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "# Model training function\n",
        "def train(model, iterator, optimizer=optimizer, criterion=criterion, clip=1):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    total_correct = 0\n",
        "    total_count = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        src = batch.text.to(device)\n",
        "        trg = batch.label.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src)\n",
        "        \n",
        "        total_correct += torch.sum(torch.eq(output.argmax(1), trg))\n",
        "        total_count+=len(trg)\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward() \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    print(f'correct: {total_correct}/{total_count}')\n",
        "    mean_loss = epoch_loss / len(iterator)\n",
        "    scheduler.step(mean_loss)\n",
        "    return mean_loss # mean loss"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4a99c18DNip",
        "outputId": "6583add5-84d0-498a-8f6c-e1a34de9b076"
      },
      "source": [
        "# loop and train our model\n",
        "total_epoch = 120\n",
        "for epoch in range(total_epoch):\n",
        "  result = train(model=model, iterator=train_iterator)\n",
        "  print(f'Epoch {epoch} -->', result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "correct: 12413/25000\n",
            "Epoch 0 --> 0.7105521597862243\n",
            "correct: 12536/25000\n",
            "Epoch 1 --> 0.6947320268154145\n",
            "correct: 12634/25000\n",
            "Epoch 2 --> 0.694028380393982\n",
            "correct: 12366/25000\n",
            "Epoch 3 --> 0.6939971520900726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dH45-V1kEDxs",
        "outputId": "2d55b7a2-4904-410a-fceb-880374303851"
      },
      "source": [
        "# function to experiment movie review sentences\n",
        "import spacy\n",
        "\n",
        "!python -m spacy download en # dwonload english from spacy\n",
        "\n",
        "sp = spacy.load('en')\n",
        "\n",
        "\n",
        "def predict(sentence):\n",
        "\n",
        "  if type(sentence) == str:\n",
        "    tokanized_sentence = [word.text for word in sp.tokenizer(sentence)]\n",
        "  else:\n",
        "    tokanized_sentence = sentence\n",
        "\n",
        "\n",
        "  input_data = [SRC.vocab.stoi[word.lower()] for word in tokanized_sentence]\n",
        "  input_data = torch.tensor(input_data, dtype=torch.int64).unsqueeze(1).to(device)\n",
        "\n",
        "\n",
        "  model.eval()\n",
        "  output = model(input_data)\n",
        "  # print(output)\n",
        "  predict = output.argmax(1)\n",
        "  predict = predict.squeeze(0)\n",
        "  print(output)\n",
        "\n",
        "  if predict>0:\n",
        "    return \"---->> Positive Review\"\n",
        "  else:\n",
        "    return '---->> Negative Review'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.62.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6XKyB13EFqi"
      },
      "source": [
        "predict('i have enjoyed this movie') # predict funciton will predict if this is positive or negative review."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-E12glbEHQ6"
      },
      "source": [
        "# 검증세트까지"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlnvhrgW5epQ"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=3e-3)\n",
        "\n",
        "# defining learnig rate scheduler (optional)\n",
        "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "# Model training function\n",
        "def train(model, iterator, optimizer=optimizer, criterion=criterion, clip=1):\n",
        "    model.train()\n",
        "    for b, batch in enumerate(iterator):\n",
        "      x, y = batch.text.to(device), batch.label.to(device)\n",
        "      y.data.sub_(1)  # 레이블 값을 0과 1로 변환\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      logit = model(x)\n",
        "      loss = criterion(output, y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "def evaluate(model, val_iter):\n",
        "    \"\"\"evaluate model\"\"\"\n",
        "    model.eval()\n",
        "    corrects, total_loss = 0, 0\n",
        "    for batch in val_iter:\n",
        "        x, y = batch.text.to(device), batch.label.to(device)\n",
        "        y.data.sub_(1) # 레이블 값을 0과 1로 변환\n",
        "        logit = model(x)\n",
        "        loss = criterion(output, y, reduction='sum')\n",
        "        total_loss += loss.item()\n",
        "        corrects += (output.argmax(1).view(y.size()).data == y.data).sum()\n",
        "    size = len(val_iter.dataset)\n",
        "    avg_loss = total_loss / size\n",
        "    avg_accuracy = 100.0 * corrects / size\n",
        "    return avg_loss, avg_accuracy"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "1XkviV_55yuo",
        "outputId": "4c75ad22-7844-44fd-b4fc-d9b1a42c4fd6"
      },
      "source": [
        "EPOCHS = 10\n",
        "best_val_loss = None\n",
        "for e in range(1, EPOCHS+1):\n",
        "  train(model=model, iterator=train_iter)\n",
        "  val_loss, val_accuracy = evaluate(model, val_iter)\n",
        "\n",
        "  print(\"[Epoch: %d] val loss : %5.2f | val accuracy : %5.2f\" % (e, val_loss, val_accuracy))\n",
        "\n",
        "  # 검증 오차가 가장 적은 최적의 모델을 저장\n",
        "  if not best_val_loss or val_loss < best_val_loss:\n",
        "      if not os.path.isdir(\"snapshot\"):\n",
        "          os.makedirs(\"snapshot\")\n",
        "      torch.save(model.state_dict(), './snapshot/txtclassification.pt')\n",
        "      best_val_loss = val_loss"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-578f4aaa2a86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbest_val_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-27f1520869d2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iovvjREW51GP"
      },
      "source": [
        "# function to experiment movie review sentences\n",
        "import spacy\n",
        "\n",
        "!python -m spacy download en # dwonload english from spacy\n",
        "\n",
        "sp = spacy.load('en')\n",
        "\n",
        "\n",
        "def predict(sentence):\n",
        "\n",
        "  if type(sentence) == str:\n",
        "    tokanized_sentence = [word.text for word in sp.tokenizer(sentence)]\n",
        "  else:\n",
        "    tokanized_sentence = sentence\n",
        "\n",
        "\n",
        "  input_data = [SRC.vocab.stoi[word.lower()] for word in tokanized_sentence]\n",
        "  input_data = torch.tensor(input_data, dtype=torch.int64).unsqueeze(1).to(device)\n",
        "\n",
        "\n",
        "  model.eval()\n",
        "  output = model(input_data)\n",
        "  # print(output)\n",
        "  predict = output.argmax(1)\n",
        "  predict = predict.squeeze(0)\n",
        "  print(output)\n",
        "\n",
        "  if predict>0:\n",
        "    return \"---->> Positive Review\"\n",
        "  else:\n",
        "    return '---->> Negative Review'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z94yqM0i52Tw"
      },
      "source": [
        "predict('i have enjoyed this movie') # predict funciton will predict if this is positive or negative review."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}